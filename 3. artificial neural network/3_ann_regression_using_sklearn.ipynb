{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Regression\n",
    "\n",
    "We'll use the same Boston Housing Dataset as we used in section **Basic ANN**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()\n",
    "num_test = 10  # the last 10 samples as testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset.\n",
    "\n",
    "To be fair, let's use the same method as in the **Basic ANN** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "X_train = boston.data[:-num_test, :]\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "y_train = boston.target[:-num_test].reshape(-1, 1)\n",
    "X_test = boston.data[-num_test:, :]\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test = boston.target[-num_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define simple MLP Model\n",
    "\n",
    "Let's use the same parameter also!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 20\n",
    "learning_rate = 0.1\n",
    "n_iter = 2000\n",
    "\n",
    "model = MLPRegressor(random_state=1, max_iter=n_iter, hidden_layer_sizes=n_hidden, learning_rate_init=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=20, learning_rate_init=0.1, max_iter=2000,\n",
       "             random_state=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16.38401042 18.34344229 21.0470215  18.84935037 19.71511553 25.42995242\n",
      " 24.19397524 31.03729243 27.58361438 23.201022  ]\n",
      "[19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.32677820446859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "print(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this is worse than our basic ANN. But, this is no model tuning at all! You can play with another params in the **MLPRegressor** function os scikit-learn."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
